{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "vecmodel = KeyedVectors.load_word2vec_format('../../../GoogleNews-vectors-negative300.bin.gz', binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Lambda\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Conv2D, MaxPooling2D,Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "from scipy.stats.stats import pearsonr   \n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entailment_judgment</th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTAILMENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entailment_judgment  pair_ID  relatedness_score  \\\n",
       "0             NEUTRAL      1.0                4.5   \n",
       "1             NEUTRAL      2.0                3.2   \n",
       "2          ENTAILMENT      3.0                4.7   \n",
       "3             NEUTRAL      5.0                3.4   \n",
       "4             NEUTRAL      9.0                3.7   \n",
       "\n",
       "                                          sentence_A  \\\n",
       "0  A group of kids is playing in a yard and an ol...   \n",
       "1  A group of children is playing in the house an...   \n",
       "2  The young boys are playing outdoors and the ma...   \n",
       "3  The kids are playing outdoors near a man with ...   \n",
       "4  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  \n",
       "0  A group of boys in a yard is playing and a man...  \n",
       "1  A group of kids is playing in a yard and an ol...  \n",
       "2  The kids are playing outdoors near a man with ...  \n",
       "3  A group of kids is playing in a yard and an ol...  \n",
       "4  A group of kids is playing in a yard and an ol...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = \"['pair_ID', 'sentence_A', 'sentence_B', 'relatedness_score','entailment_judgment']\"\n",
    "train_df = pd.read_csv(\"../data/enhance_traindata.csv\", sep='\\t')\n",
    "trial_df = pd.read_csv(\"../data/SemEval2014_dataset/SICK_trial.txt\", sep='\\t')\n",
    "test_df = pd.read_csv(\"../data/SemEval2014_dataset/SICK_test_annotated.txt\", sep='\\t')\n",
    "\n",
    "texts = []\n",
    "BASE_DIR = ''\n",
    "TEXT_DATA_DIR = os.path.join('../data/SemEval2014_dataset/')\n",
    "MAX_SEQUENCE_LENGTH = 75\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "# VALIDATION_SPLIT = 0.2\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create word_id\n",
    "merged = train_df['sentence_A'].tolist()\n",
    "merged.extend(train_df['sentence_B'].tolist())\n",
    "merged.extend(trial_df['sentence_A'].tolist())\n",
    "merged.extend(trial_df['sentence_B'].tolist())\n",
    "merged.extend(test_df['sentence_A'].tolist())\n",
    "merged.extend(test_df['sentence_B'].tolist())\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(merged)\n",
    "sequences = tokenizer.texts_to_sequences(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "word_index = tokenizer.word_index\n",
    "# prepare embedding matrix\n",
    "num_words = max(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in vecmodel.vocab:\n",
    "        embedding_vector = vecmodel[word]\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokenized_padded_data(data):\n",
    "    \n",
    "#     t = Tokenizer(num_words=MAX1_NB_WORDS)\n",
    "#     t.fit_on_texts(data)\n",
    "#     r = RegexpTokenizer(r'\\w+')\n",
    "#     r.tokenize(data)\n",
    "    padded_data = []\n",
    "    for d in data:\n",
    "        r = RegexpTokenizer(r'\\w+')\n",
    "        c = r.tokenize(d)\n",
    "        seq = tokenizer.texts_to_sequences(c)\n",
    "        seq = [item for sublist in seq for item in sublist]\n",
    "        padded_data.append(seq)    \n",
    "    padded_data = pad_sequences(padded_data, maxlen=MAX_SEQUENCE_LENGTH) \n",
    "    return padded_data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# get_tokenized_padded_data(['The young \"boys\" @ are playing outdoors and the man is smiling nearby','Nobody is riding the bicycle on one wheel'])\n",
    "def get_target_value(data):\n",
    "    \n",
    "    target= []\n",
    "    for i in range(len(data)):\n",
    "        target.append(int(round(data[i])));\n",
    "    return target\n",
    "\n",
    "\n",
    "def get_target_category(data):\n",
    "    data = get_target_value(data)\n",
    "    encoder = LabelEncoder()\n",
    "    class_val = [0,1,2,3,4,5] \n",
    "    encoder.fit(class_val)\n",
    "    encoded_Y = encoder.transform(data)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    target = keras.utils.to_categorical(encoded_Y)\n",
    "    return target\n",
    "\n",
    "def pear_coef(y_true, y_pred):\n",
    "    pearson_r, update_op = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true)\n",
    "    return pearson_r\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "   \n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x)\n",
    "    my = K.mean(y)\n",
    "    xm, ym = (x - mx), (y-my)\n",
    "    r_num = K.sum(xm * ym)\n",
    "    r_den = K.sqrt(K.sum(K.square(xm))) * K.sqrt(K.sum(K.square(ym)))\n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   1  87   6 219   3  16   4   1 616   5  25 285  10   3  42\n",
      "   4   2 402]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xA_train = get_tokenized_padded_data(train_df['sentence_A'].tolist())\n",
    "print(xA_train[0])\n",
    "xA_val = get_tokenized_padded_data(trial_df['sentence_A'].tolist())\n",
    "xA_test = get_tokenized_padded_data(test_df['sentence_A'].tolist())\n",
    "\n",
    "xB_train = get_tokenized_padded_data(train_df['sentence_B'].tolist())\n",
    "xB_val = get_tokenized_padded_data(trial_df['sentence_B'].tolist())\n",
    "xB_test = get_tokenized_padded_data(test_df['sentence_B'].tolist())\n",
    "\n",
    "y_train = get_target_category(train_df['relatedness_score'].tolist())\n",
    "y_val = get_target_category(trial_df['relatedness_score'].tolist())\n",
    "y_test = get_target_category(test_df['relatedness_score'].tolist())\n",
    "\n",
    "# y_train = get_target_value(train_df['relatedness_score'].tolist())\n",
    "# y_val = get_target_value(trial_df['relatedness_score'].tolist())\n",
    "# y_test = get_target_value(test_df['relatedness_score'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group of kids is playing in a yard and an old man is standing in the background\n",
      "A group of boys in a yard is playing and a man is standing in the background\n",
      "[ 0.  0.  0.  0.  0.  1.]\n",
      "(15065, 6)\n",
      "(500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_df['sentence_A'][0])\n",
    "print(train_df['sentence_B'][0])\n",
    "print(y_train[0])\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqA_input = Input(shape=(MAX_SEQUENCE_LENGTH,),)\n",
    "seqB_input = Input(shape=(MAX_SEQUENCE_LENGTH,),)\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "x_A = embedding_layer(seqA_input)\n",
    "x_B = embedding_layer(seqB_input)\n",
    "x = keras.layers.Concatenate()([x_A, x_B])\n",
    "reshape = Reshape((2,MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))(x)\n",
    "x = Convolution2D(filters=EMBEDDING_DIM,kernel_size=(1,1),activation=\"relu\",kernel_initializer='he_uniform')(reshape)\n",
    "x = MaxPooling2D(pool_size=(1,MAX_SEQUENCE_LENGTH),strides=(1,1))(x)\n",
    "\n",
    "x_A = Lambda(lambda x: x[:, 0])(x)\n",
    "x_B = Lambda(lambda x: x[:, 1])(x)\n",
    "\n",
    "diff = keras.layers.Subtract()([x_A, x_B])\n",
    "prod = keras.layers.Multiply()([x_A, x_B])\n",
    "\n",
    "\n",
    "nn = keras.layers.Concatenate()([diff, prod])\n",
    "\n",
    "\n",
    "\n",
    "nn = Dense(300, activation='tanh',kernel_initializer='he_uniform')(nn)\n",
    "nn = GlobalMaxPooling1D()(nn)\n",
    "preds = Dense(6, activation='softmax')(nn)\n",
    "model = Model(inputs=[seqA_input,seqB_input], outputs=preds)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt,\n",
    "              metrics=[correlation_coefficient,'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15065 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "15065/15065 [==============================] - 26s 2ms/step - loss: 0.0687 - correlation_coefficient: 0.7110 - acc: 0.7059 - val_loss: 0.1264 - val_correlation_coefficient: 0.3924 - val_acc: 0.4440\n",
      "Epoch 2/10\n",
      "15065/15065 [==============================] - 27s 2ms/step - loss: 0.0628 - correlation_coefficient: 0.7402 - acc: 0.7389 - val_loss: 0.1224 - val_correlation_coefficient: 0.4137 - val_acc: 0.4380\n",
      "Epoch 3/10\n",
      "15065/15065 [==============================] - 27s 2ms/step - loss: 0.0597 - correlation_coefficient: 0.7548 - acc: 0.7521 - val_loss: 0.1247 - val_correlation_coefficient: 0.4110 - val_acc: 0.4320\n",
      "Epoch 4/10\n",
      "15065/15065 [==============================] - 27s 2ms/step - loss: 0.0534 - correlation_coefficient: 0.7846 - acc: 0.7794 - val_loss: 0.1294 - val_correlation_coefficient: 0.3922 - val_acc: 0.4320\n",
      "Epoch 5/10\n",
      "15065/15065 [==============================] - 27s 2ms/step - loss: 0.0497 - correlation_coefficient: 0.8014 - acc: 0.7940 - val_loss: 0.1288 - val_correlation_coefficient: 0.4007 - val_acc: 0.4380\n",
      "Epoch 6/10\n",
      "15065/15065 [==============================] - 27s 2ms/step - loss: 0.0487 - correlation_coefficient: 0.8054 - acc: 0.8031 - val_loss: 0.1258 - val_correlation_coefficient: 0.4256 - val_acc: 0.4580\n",
      "Epoch 7/10\n",
      "15065/15065 [==============================] - 28s 2ms/step - loss: 0.0444 - correlation_coefficient: 0.8247 - acc: 0.8231 - val_loss: 0.1286 - val_correlation_coefficient: 0.4106 - val_acc: 0.4420\n",
      "Epoch 8/10\n",
      "15065/15065 [==============================] - 30s 2ms/step - loss: 0.0423 - correlation_coefficient: 0.8336 - acc: 0.8312 - val_loss: 0.1308 - val_correlation_coefficient: 0.3992 - val_acc: 0.4460\n",
      "Epoch 9/10\n",
      "11400/15065 [=====================>........] - ETA: 6s - loss: 0.0420 - correlation_coefficient: 0.8350 - acc: 0.8325"
     ]
    }
   ],
   "source": [
    "model.fit([xA_train,xB_train], y_train,\n",
    "          batch_size=100,\n",
    "          epochs=10,validation_data=([xA_val,xB_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4927/4927 [==============================] - 4s 761us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11708173517350229, 0.43258842115763213, 0.45747919972537615]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([xA_test,xB_test], y_test, batch_size=339)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
